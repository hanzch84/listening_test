import streamlit as st
from pathlib import Path
from openai import OpenAI
import os
from dotenv import load_dotenv
from collections import Counter
import re
import random
from pydub import AudioSegment
from io import BytesIO

# CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown(
    """
    <style>
        a:link {
            color : #ff4b4b;
        }
        a:visited {
            color : #ffa657;
        }
        a:hover {
            color : red;
        }
        a:active {
            color : green
        }
    h1{font-size: 36px;}
    div.stButton > button,div.stDownloadButton > button {
        height: 54px;
        font-size: 24px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

def is_input_exist(text):
    pattern = re.compile(r'[a-zA-Zê°€-í£]')
    return not bool(pattern.search(text))

def which_eng_kor(input_s):
    count = Counter(input_s)
    k_count = sum(count[c] for c in count if ord('ê°€') <= ord(c) <= ord('í£'))
    e_count = sum(count[c] for c in count if 'a' <= c.lower() <= 'z')
    return "ko" if k_count > e_count else "en"

def extract_question(text):
    match = re.match(r'(\d{1,2}\s*\.?\s*ë²ˆ?)\s*(.*)', text)
    if match:
        number = match.group(1).strip()
        question = match.group(2).strip()
        return number, question
    else:
        return None, text.lstrip()

def merge_lines(lines):
    merged = []
    current_sentence = ""
    for line in lines:
        line = line.strip()
        if line.endswith('.') or line.endswith('?') or line.endswith('!'):
            current_sentence += " " + line
            merged.append(current_sentence.strip())
            current_sentence = ""
        else:
            current_sentence += " " + line
    if current_sentence:
        merged.append(current_sentence.strip())
    return merged

def get_voice(option, idx, gender):
    if option in ["random", "order"]:
        if gender == "female":
            voices = ['alloy', 'fable', 'nova', 'shimmer']
        else:
            voices = ['echo', 'onyx']
        if option == "random":
            selected_voice = random.choice(voices)
            print(f"Randomly selected {gender} voice: {selected_voice}")
            return selected_voice
        else:
            selected_voice = voices[idx % len(voices)]
            print(f"Sequentially selected {gender} voice: {selected_voice}")
            return selected_voice
    else:
        print(f"Selected {gender} voice: {option}")
        return option

load_dotenv()

api_key = os.getenv('OPENAI_API_KEY')

if not api_key:
    st.error("API key not found. Please set the OPENAI_API_KEY environment variable.")
else:
    client = OpenAI(api_key=api_key)

    st.title("ë“£ê¸°í‰ê°€ ìŒì› ë§Œë“¤ê¸°: En Listen")
    col_speed, col_subheader = st.columns([5, 7])
    speed_rate = col_speed.slider("ìŒì„± ì†ë„(ë°°)", 0.55, 1.85, 1.0, 0.05)
    col_subheader.markdown('<p style="font-size:10pt; color: #6b6c70;text-align: right;">ì œì‘: êµì‚¬ ë°•í˜„ìˆ˜, ë²„ê·¸ ë° ê°œì„  ë¬¸ì˜: <a href="mailto:hanzch84@gmail.com">hanzch84@gmail.com</a></p>', unsafe_allow_html=True)
    col_subheader.markdown('<p style="font-size:14pt; color: #6b6c70;text-align: right;"><a href="https://platform.openai.com/docs/guides/text-to-speech/voice-options">ìŒì„± ì˜µì…˜ ë¯¸ë¦¬ë“£ê¸°(openai TTS api overview page)</a></p>', unsafe_allow_html=True)
    col_voice, col_interval = st.columns([10, 3])
    ko_option = col_voice.radio("í•œêµ­ì–´ ìŒì„±", ['alloy', 'fable', 'nova', 'shimmer', 'echo', 'onyx'], key="korean_option", index=2, horizontal=True, help="í•œêµ­ì–´ ìŒì„±ì„ ì„ íƒí•˜ì„¸ìš”.")
    female_voice = col_voice.radio("ì—¬ì„± ìŒì„±", ['alloy', 'fable', 'nova', 'shimmer', "order", "random"], key="female_option", horizontal=True, help="ì—¬ì„± ìŒì„±ì„ ì„ íƒí•˜ì„¸ìš”. randomì€ ë¬¸ì œë§ˆë‹¤ ë¬´ì‘ìœ„ì˜ ìŒì„±ì„ ì„ íƒí•©ë‹ˆë‹¤. sequentialì€ ë¬¸ì œë§ˆë‹¤ ìŒì„±ì„ ì°¨ë¡€ë¡œ ë°”ê¿” ì¤ë‹ˆë‹¤.")
    male_voice = col_voice.radio("ë‚¨ì„± ìŒì„±", ['echo', 'onyx', "order", "random"], key="male_option", horizontal=True, help="ë‚¨ì„± ìŒì„±ì„ ì„ íƒí•˜ì„¸ìš”. randomì€ ë¬¸ì œë§ˆë‹¤ ë¬´ì‘ìœ„ì˜ ìŒì„±ì„ ì„ íƒí•©ë‹ˆë‹¤. sequentialì€ ë¬¸ì œë§ˆë‹¤ ìŒì„±ì„ ì°¨ë¡€ë¡œ ë°”ê¿” ì¤ë‹ˆë‹¤.")

    print(f"Selected Korean voice: {ko_option}")
    print(f"Selected female voice: {female_voice}")
    print(f"Selected male voice: {male_voice}")

    interline = 1000*col_interval.slider("ëŒ€ì‚¬ ê°„ê²©(s)", min_value=0.2, max_value=2.0, value=0.7, step=0.1, key="interline", disabled=False, help="ë¬¸ì¥ ì‚¬ì´ì˜ ë¬´ìŒ êµ¬ê°„ ê¸¸ì´")
    internum = col_interval.slider("ë¬¸ì œ ê°„ê²©(s)", min_value=1, max_value=25, value=10, key="internum", disabled=False, help="ë¬¸ì œì™€ ë¬¸ì œ ì‚¬ì´ì˜ ë¬´ìŒ êµ¬ê°„ ê¸¸ì´")

    # ë¬´ìŒì„ ë¯¸ë¦¬ ìƒì„±
    interline_silence = AudioSegment.silent(duration=interline)
    internum_silence = AudioSegment.silent(duration=internum * 1000)

    if 'female_sequence' not in st.session_state:
        st.session_state.female_sequence = 0
    if 'male_sequence' not in st.session_state:
        st.session_state.male_sequence = 0

    col_btn2, col_btn3 = st.columns([10, 3])
    success_message = st.empty()
    warning_message = st.empty()
    audio_placeholder = col_btn2.empty()
    if 'input_text' not in st.session_state:
        st.session_state.input_text = """1. ë‹¤ìŒì„ ë“£ê³ , ë‚¨ìê°€ í•˜ëŠ” ë§ì˜ ëª©ì ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ê²ƒì„ ê³ ë¥´ì‹œì˜¤.
M: Hello, Maplewood High School students.
This is your school librarian, Mr. Johnson. 

W: Number One.
    testing and tasting the app.

W: Number Three.
    toasting and twisting the app.

W: Number Five.
    tossing and trusting the app.


2ë²ˆ ë‹¤ìŒ ëŒ€í™”ë¥¼ ë“£ê³ , ì—¬ìì˜ ì˜ê²¬ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ê²ƒì„ ê³ ë¥´ì‹œì˜¤.
M: Hi, Sweetie.
W: Could you keep the orange peels for me?
M: Why? What are you going to do with them?
W: Iâ€™m planning to use them to make a natural cleaner."""

    st.code("""'ëŒ€ë³¸ ì…ë ¥ë€'ì˜ ì˜ˆì‹œë¥¼ ì§€ìš°ê³  ë“£ê¸°í‰ê°€ ëŒ€ë³¸ì„ ì…ë ¥í•˜ì„¸ìš”.
ì•ì— ìˆ«ìì™€ 'ë²ˆ'ë˜ëŠ” '.'ì„ ì“°ë©´ ë¬¸ì œë²ˆí˜¸ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤.
ì•ì— ìŒì„±ì§€í‘œ(M:ë‚¨ì„±,W:ì—¬ì„±)ë¥¼ ë„£ìœ¼ë©´ í•´ë‹¹ ì„±ë³„ ìŒì„±ìœ¼ë¡œ ë°”ë€ë‹ˆë‹¤.
'random'ì€ ë¬¸ì œë§ˆë‹¤ í•´ë‹¹ ì„±ë³„ì˜ ìŒì„±ì„ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
'order'ëŠ” ë¬¸ì œë§ˆë‹¤ í•´ë‹¹ ì„±ë³„ì˜ ìŒì„±ì„ ìˆœì„œëŒ€ë¡œ ë°”ê¿” ì¤ë‹ˆë‹¤.
ë¬¸ì¥, ë¬¸ì œ ê°„ê²©ì„ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê°ìƒ‰ëœ ì˜ˆì‹œ ëŒ€ë³¸ ì›ë³¸ ì¶œì²˜:EBS)""", language="haskell")
    st.session_state.input_text = st.text_area("ëŒ€ë³¸ ì…ë ¥ë€", st.session_state.input_text, key="input_area", height=max(st.session_state.input_text.count('\n') * 26 + 10, 400))

    if col_interval.button("ğŸ”Š ìŒì› ìƒì„±í•˜ê¸°", disabled=is_input_exist(st.session_state.input_text),):
        print("Generating audio...")

        overlay_container = st.empty()
        overlay_container.markdown("""
        <style>
        .overlay {
            position: fixed;top: 0;left: 0;width: 100%;height: 100%;
            background: rgba(0, 0, 0, 0.7);z-index: 999;display: flex;
            justify-content: center;align-items: center;                }
        .spinner {margin-bottom: 10px;}
        </style>
        <div class="overlay"><div><div class="spinner">
                    <span class="fa fa-spinner fa-spin fa-3x"></span>
                </div><div style="color: white;">ìŒì›ì„ ì¶œë ¥í•˜ëŠ” ì¤‘...</div></div></div>""", unsafe_allow_html=True)
        try:
            speech_file_path = Path("speech.mp3")
            input_text = st.session_state.input_text
            lines = input_text.split('\n')
            sentences = merge_lines(lines)
            tts = AudioSegment.silent(duration=0)  # ì´ˆê¸° ìŒì„±
            current_number = None
            is_first_question = True  # ì²« ë¬¸ì œ ì—¬ë¶€ í™•ì¸ ë³€ìˆ˜ ì¶”ê°€

            current_female_voice = get_voice(female_voice, st.session_state.female_sequence, "female")
            current_male_voice = get_voice(male_voice, st.session_state.male_sequence, "male")
            current_voice = None

            for sentence in sentences:
                sentence = sentence.lstrip()
                lang = which_eng_kor(sentence)

                number, sentence = extract_question(sentence)

                if number and number != current_number:
                    current_number = number
                    if female_voice in ["random", "order"]:
                        st.session_state.female_sequence += 1
                        current_female_voice = get_voice(female_voice, st.session_state.female_sequence, "female")
                    if male_voice in ["random", "order"]:
                        st.session_state.male_sequence += 1
                        current_male_voice = get_voice(male_voice, st.session_state.male_sequence, "male")

                    if not is_first_question:  # ì²« ë¬¸ì œ ì•ì—ëŠ” ë¬´ìŒì„ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                        tts += internum_silence  # ë¬¸ì œ ê°„ ë¬´ìŒ ì¶”ê°€
                    is_first_question = False

                if re.match(r'W:|W :', sentence):
                    current_voice = current_female_voice
                elif re.match(r'M:|M :', sentence):
                    current_voice = current_male_voice
                elif lang == 'ko':
                    current_voice = ko_option
                else:
                    if not current_voice:
                        current_voice = current_male_voice if current_number and current_number[-1] == '.' else current_female_voice

                text_to_convert = f"{number[:-1]}ë²ˆ.\n'.....'\n {sentence}" if number else sentence

                if text_to_convert.strip():
                    response = client.audio.speech.create(
                        model="tts-1",
                        voice=current_voice,
                        input=text_to_convert,
                        speed=speed_rate
                    )

                    # response.iter_bytes()ë¥¼ í†µí•´ ìƒì„±ëœ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
                    audio_bytes = BytesIO(b"".join(response.iter_bytes()))
                    audio_chunk = AudioSegment.from_file(audio_bytes, format="mp3")
                    tts += audio_chunk

                    tts += interline_silence  # ë¬¸ì¥ ê°„ ë¬´ìŒ ì¶”ê°€

            tts.export(speech_file_path, format="mp3")
            st.session_state.speech_file_path = str(speech_file_path)
            st.session_state.success_message = "ìŒì„± ë³€í™˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
            st.session_state.en_warning_message = "ê³ ì§€ ì‚¬í•­: ì´ ëª©ì†Œë¦¬ëŠ” ì¸ê³µì§€ëŠ¥(AI)ìœ¼ë¡œ ìƒì„±ëœ ê²ƒì´ë©°, ì‹¤ì œ ì‚¬ëŒì˜ ëª©ì†Œë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤."
            print("Audio file saved successfully.")

        except Exception as e:
            st.session_state.success_message = f"An error occurred: {e}"
            print(f"An error occurred: {e}")
        overlay_container.empty()
        st.balloons()

    if 'speech_file_path' in st.session_state:
        success_message.success(st.session_state.success_message)
        warning_message.warning(st.session_state.en_warning_message, icon="ğŸš¨")
        audio_placeholder.audio(st.session_state.speech_file_path)

        with open(st.session_state.speech_file_path, "rb") as file:
            btn = col_btn3.download_button(
                label="ğŸ“¥ MP3 ë‹¤ìš´ë¡œë“œ",
                data=file,
                file_name="speech.mp3",
                mime="audio/mpeg"
            )
